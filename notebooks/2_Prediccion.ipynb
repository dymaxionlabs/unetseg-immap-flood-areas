{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zonas inundables\n",
    "\n",
    "## 2_ Predicción\n",
    "\n",
    "Este notebook genera la prediccion del modelo sobre un nuevo dataset. Para ello primero descargamos las imagenes satelitales y luego con satproc generamos el dataset de predicción con el formato necesario para el modelo de ML\n",
    "\n",
    "\n",
    "**Definicion de los parametros para la predicción**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-05 17:38:26.246319: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    }
   ],
   "source": [
    "from unetseg.predict import PredictConfig, predict\n",
    "from unetseg.evaluate import plot_data_results\n",
    "import subprocess\n",
    "import os\n",
    "\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "BASE_PATH = \"../\"\n",
    "PATH_S1_IMAGES_PREDICT = f\"{BASE_PATH}/images/\"\n",
    "#model\n",
    "SIZE      = 160\n",
    "STEP_SIZE = 160\n",
    "\n",
    "MODEL_VERSION = \"v0\"\n",
    "MODEL = f'UNet_TEST_160x160_spe100_7N_flood_aeras_colombia_{MODEL_VERSION}.h5'\n",
    "\n",
    "BUCKET_RESULTS = \"gs://dym-indunor-temp/immap/v3_1/floods_annotations/results/pred_500/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descarga de las imagenes de predicción"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Descarga las imagenes del bucket"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Satproc\n",
    "\n",
    "Con esta herramienta genereamos un dataset de imágenes de predicción que, a diferencia del de entrenamiento, solo contiene imágenes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_files   = f'{PATH_S1_IMAGES_PREDICT}/*prediction*.tif' #carpeta a las imagenes\n",
    "dataset_folder  = f'{BASE_PATH}/dataset/data_predict/pred_500/{str(SIZE)}_{str(STEP_SIZE)}/' #carpeta de destino del dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Rasters:   0%|                                            | 0/1 [00:00<?, ?it/s]\r\n",
      "\r",
      "dataset_prediction_500m_epsg4326.tif windows:   0%|     | 0/216 [00:00<?, ?it/s]\u001b[A\r",
      "dataset_prediction_500m_epsg4326.tif windows: 100%|#| 216/216 [00:00<00:00, 1177\r\n",
      "\r",
      "Rasters: 100%|###################################| 1/1 [00:00<00:00, 122.88it/s]\r\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!satproc_extract_chips \\\n",
    "                $path_to_files \\\n",
    "                -o  $dataset_folder \\\n",
    "                --size $SIZE \\\n",
    "                --step-size $STEP_SIZE \\\n",
    "                --rescale \\\n",
    "                --rescale-mode percentiles  --lower-cut 0 --upper-cut 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pasamos la ruta de las imágenes de predicción y la ruta donde queremos que se guarde el resultado.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediccion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos la configuración para la predicción. Debemos pasar la ruta de las imágenes en el dataset de predicción, que es la ruta de salida de la línea anterior, y la correspondiente al modelo que entrenamos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNet_TEST_160x160_spe100_7N_flood_aeras_colombia_v0.h5\r\n"
     ]
    }
   ],
   "source": [
    "!ls ../data/weights/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total images to predict (..//dataset/data_predict/pred_500/160_160/images/*.tif): 216\n",
      "After skipping existing results: 216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                                | 0/54 [00:00<?, ?it/s]2022-07-05 17:40:08.535724: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2022-07-05 17:40:08.536762: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2299995000 Hz\n",
      "2022-07-05 17:40:08.911359: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-07-05 17:40:10.180795: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256\n",
      "2022-07-05 17:40:10.241018: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: \n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n",
      "2022-07-05 17:40:11.015790: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 54/54 [00:25<00:00,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Input file size is 1915, 2785\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "predict_config = PredictConfig(\n",
    "\n",
    "        images_path   = dataset_folder, # ruta a las imagenes sobre las cuales queremos predecir\n",
    "        results_path  = f'{BASE_PATH}/dataset/data_results/pred_500/{MODEL_VERSION}/{str(SIZE)}_{str(STEP_SIZE)}/'\n",
    ", # ruta de destino para nuestra predicción\n",
    "        batch_size  = 4,\n",
    "        model_path  = os.path.join(BASE_PATH +'data/weights', MODEL),  #  ruta al modelo (.h5)\n",
    "        height = 160,\n",
    "        width  = 160,\n",
    "        n_channels = 6,\n",
    "        n_classes  = 1,\n",
    "        class_weights = [1])\n",
    "\n",
    "#A continuación ejecutamos la predicción\n",
    "predict(predict_config)    \n",
    "#plot_data_results(num_samples=2, fig_size=(2, 2), predict_config=predict_config, img_ch =2, n_bands=3)\n",
    "\n",
    "#create VTR\n",
    "!rm tmp_list.txt\n",
    "\n",
    "vrt_path        = f'{predict_config.results_path}/../all.vrt' # ruta de destino para nuestra predicción\n",
    "tif_path        = f'{predict_config.results_path}/../all_{MODEL_VERSION}.tif'\n",
    "predict_results = f'{predict_config.results_path}/*tif' # ruta de destino para nuestra predicción\n",
    "\n",
    "filenames = glob.glob(predict_results)\n",
    "\n",
    "with open('tmp_list.txt', 'w') as f:\n",
    "    for line in filenames:\n",
    "        f.write(line)\n",
    "        f.write('\\n')\n",
    "!gdalbuildvrt -input_file_list tmp_list.txt $vrt_path\n",
    "\n",
    "!gdal_translate -of GTiff -co COMPRESS=DEFLATE -co PREDICTOR=2 -co ZLEVEL=9 $vrt_path $tif_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file://..//dataset/data_results/pred_500/v0/160_160//../all_v0.tif [Content-Type=image/tiff]...\n",
      "/ [1/1 files][  1.4 MiB/  1.4 MiB] 100% Done                                    \n",
      "Operation completed over 1 objects/1.4 MiB.                                      \n"
     ]
    }
   ],
   "source": [
    "!gsutil -m cp -r $tif_path $BUCKET_RESULTS "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNKlws8+6PcuvJrSWdSmTxJ",
   "include_colab_link": true,
   "name": "2 - Entrenamiento",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "tf-gpu-py38",
   "language": "python",
   "name": "tf-gpu-py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
